{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f023c23",
   "metadata": {},
   "source": [
    "# STA130 LEC 07 (Oct 21)\n",
    "\n",
    "## .THE STA130 COURSE PROJECT.<br>...HAS ENTERED THE BUILDING..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a7d20",
   "metadata": {},
   "source": [
    "### 9:10/1:10 A word from the CO (Commanding Officer)<br><sub>My Dad's USAF Pentagon so I love my weird acronyms like this one</sub>\n",
    "    \n",
    "CO: **Christine Ovcaric**  \n",
    "Program Manager, The Sandbox  \n",
    "Uoft Experiential Learning Hub\n",
    "\n",
    "The **Community Engaged Learning (CEL)** Project\n",
    "- **Dr. Heather Hermant** (Community Partnerships)\n",
    "- **Dr. Michelle Arnot** (Pharma/Toxicology)\n",
    "- **Dr. Ashley Waggoner Denton** (Psych)\n",
    "- **Dr. Naomi Levy-Strumpf** (Human Biology)\n",
    "\n",
    "### 9:20/1:20 A fireside chat with Dr. Kiffer Card\n",
    "\n",
    "- the Scientific Director of the Canadian Alliance for Social Connection and Health\n",
    "- President and Chair for the Mental Health and Climate Change Alliance\n",
    "- President of the Island Sexual Health Community Health Centre\n",
    "- Director of Research for GenWell\n",
    "- Assistant Professor with the Faculty of Health Sciences at Simon Fraser University\n",
    "- yada yada yada blah blah blah etc. etc. etc. Dr. KC **JUST DO IT** if you see what I mean\n",
    "\n",
    "### 9:45/1:45\n",
    "\n",
    "- Sarah Shafi\n",
    "- Jazmyn Crasto\n",
    "- Samantha Rahamatali\n",
    "\n",
    "From HMB301 **Biotechnology** with **Dr. Naomi Levy-Strumpf**\n",
    "\n",
    "> Students gain an appreciation for how science, government and society drive the development of biotechnology products. Topics include emerging immunotherapies, “living therapeutics”, emerging challenges, CRISPR-based therapeutics, emerging diagnostics, and stem cells and regenerative medicine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d32ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('rmuRoAf9-bo', width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23c91d",
   "metadata": {},
   "source": [
    "## Wait, Linear Regression is just a--?<br>YES -- A Normal Distribution Model\n",
    "\n",
    "1. ~~Elvis~~ THE STA130 COURSE PROJECT HAS LEFT THE BUILDING\n",
    "\n",
    "    1. But the game isn't over: https://www.guessthecorrelation.com/\n",
    "        1. The game is afoot.\n",
    "        2. No, the game is not literally \"a foot\" -- that's just a Sherlock the Holmie's quote\n",
    "        3. **to celebrate how we gonna sleuth out this Canadian Social Connection Survey data**\n",
    "        4. and because Benedict Cumberbatch be havin' the best quotes: **\"Data, data, data. I cannot make BRICKS without CLAY\"**\n",
    "    \n",
    "|![](https://images6.fanpop.com/image/photos/36500000/Sherlock-Holmes-Sherlock-BBC1-image-sherlock-holmes-sherlock-bbc1-36580721-538-339.jpg)|![](https://i.imgflip.com/97bm6o.jpg)|\n",
    "|-|-|\n",
    "| | |\n",
    "    \n",
    "2. **Correlation IS NOT Causation?**\n",
    "\n",
    "    1. Ice Cream does not cause Shark Attacks?\n",
    "    2. Parents Height does NOT CAUSE Childs Height? \n",
    "        1. Does Height CAUSE weight? \n",
    "    3. What IS **correlation** anyway? \n",
    "    4. There are MANY kinds of associations (besides correlation) that are not actually LINEAR\n",
    "        1. And if you try to \"measure\" them with **THE LINEAR ASSOCIATION measure CORRELATION** you CAN FOR SURE get the wrong idea of \"what the picture looks like\"\n",
    "    \n",
    "3. Simple Linear Regression\n",
    "\n",
    "    1. Outcome $Y_i$\n",
    "    2. Predictor $x_i$\n",
    "    3. Intercept $\\beta_0$ coefficient\n",
    "    4. Slope $\\beta_1$ coefficient\n",
    "    5. Error term $\\epsilon_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc51076",
   "metadata": {},
   "source": [
    "### Let's Play\n",
    "\n",
    "https://www.guessthecorrelation.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658430d",
   "metadata": {},
   "source": [
    "### Correlation IS NOT Causation\n",
    "\n",
    "in the since that the following can't be true\n",
    "\n",
    "### ~~Ice Cream CAUSES Shark Attacks!!!~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd00b2d",
   "metadata": {},
   "source": [
    "|![](https://i.ibb.co/3fhg46G/dd-6-image1.jpg)|\n",
    "|-|\n",
    "|![](https://pbs.twimg.com/media/GDuW8vmXkAArDmt.jpg)|\n",
    "|![](https://biostatsquid.com/wp-content/uploads/2022/11/Slide21-1.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7bd74",
   "metadata": {},
   "source": [
    "### Correlation IS NOT Causation\n",
    "\n",
    "in the sense that there must be other interesting factors at play\n",
    "\n",
    "### Parents HEIGHTS (alone) DOES NOT CAUSES Child Height!!!\n",
    "\n",
    "Okay, so first, here's some more of that old timey shit\n",
    "- Remember, we're themeing hard on the homie Benedict Sherlock\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c7b08",
   "metadata": {},
   "source": [
    "| This is like a \"2D histogram\" of parents \"mid height\" versus their adult children's height (with the so-called \"marginal\" histogram counts there on the right) |\n",
    "|:-|\n",
    "|![](https://d3i71xaburhd42.cloudfront.net/562e90c04e43254ab35b7987e0dabd228d040e97/8-Table1-1.png)|\n",
    "\n",
    "| And these are interesting (EXTREMELY \"CLASSIC\") figures showing so-called|\"Regression to the mean\" phenomenon where relationships always \"less strong\"  |\n",
    "|-:|:-|\n",
    "|<img src=\"https://i.namu.wiki/i/Ujk5wRoPLVwPyTunKcJhuOWJtlRMjNmnvUo97obITxpudQNC_jxI-Gda9foIuVmSXwK77A6GET3ybvN2Cs21FA.webp\" width=\"500\"/>|<img src=\"https://www.cs.bu.edu/fac/snyder/cs132-book/_images/L23LinearModels_6_0.png\" width=\"500\"/>|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Load Galton's parent-child height dataset\n",
    "galton_data = sm.datasets.get_rdataset(\"GaltonFamilies\", \"HistData\").data\n",
    "\n",
    "# Select midparentHeight and childHeight for classic Galton analysis\n",
    "y = galton_data['midparentHeight']\n",
    "x = galton_data['childHeight']\n",
    "# Usually x \"predicts\" y but it's here backwards for aspect ratio purposes:\n",
    "# an ellipse shape is actually way more fkn weird to look at (for a human) than you would first think\n",
    "#x = galton_data['midparentHeight']\n",
    "#y = galton_data['childHeight']\n",
    "\n",
    "# Create a scatter plot with alpha transparency\n",
    "fig = px.scatter(galton_data, x='childHeight', y='midparentHeight', \n",
    "                 trendline='ols',  # Add a linear trendline\n",
    "                 title='Midparent vs Child Height with Trendline')\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.5))\n",
    "\n",
    "# Function to calculate the ellipse points (for the bivariate normal ellipse)\n",
    "def get_ellipse(mean, cov, n_std=1.0, num_points=100):\n",
    "    \"\"\"Generate coordinates for a 2D ellipse based on covariance matrix.\"\"\"\n",
    "    theta = np.linspace(0, 2 * np.pi, num_points)\n",
    "    circle = np.array([np.cos(theta), np.sin(theta)])  # unit circle\n",
    "\n",
    "    # Ellipse transformation: scale by sqrt(eigenvalues) and rotate by eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    ellipse_coords = np.dot(eigvecs, np.sqrt(eigvals)[:, np.newaxis] * circle * n_std)\n",
    "\n",
    "    # Shift ellipse to the mean\n",
    "    ellipse_coords[0] += mean[0]\n",
    "    ellipse_coords[1] += mean[1]\n",
    "\n",
    "    return ellipse_coords, eigvecs\n",
    "\n",
    "# Calculate covariance matrix and mean\n",
    "cov_matrix = np.cov(x, y)\n",
    "mean_vals = [np.mean(x), np.mean(y)]\n",
    "\n",
    "# Get ellipse coordinates and eigenvectors\n",
    "ellipse_coords, eigvecs = get_ellipse(mean_vals, cov_matrix, n_std=2)\n",
    "ellipse_x, ellipse_y = ellipse_coords\n",
    "\n",
    "# Get the first eigenvector (for the primary direction)\n",
    "primary_direction = eigvecs[:, 1]  # First eigenvector (primary direction)\n",
    "\n",
    "# Define the line points based on the primary direction\n",
    "line_length = 4  # Length of the primary direction line\n",
    "line_x = np.array([mean_vals[0] - line_length * 3 * primary_direction[0], \n",
    "                   mean_vals[0] + line_length * 3 * primary_direction[0]])\n",
    "line_y = np.array([mean_vals[1] - line_length * 3 * primary_direction[1], \n",
    "                   mean_vals[1] + line_length * 3 * primary_direction[1]])\n",
    "\n",
    "# Plot the ellipse\n",
    "ellipse_trace = go.Scatter(x=ellipse_x, y=ellipse_y, mode='lines',\n",
    "                           line=dict(color='green', width=2, dash='dash'),\n",
    "                           name='Covariance Ellipse')\n",
    "fig.add_trace(ellipse_trace)\n",
    "\n",
    "# Add the primary direction line through the ellipse\n",
    "primary_direction_line = go.Scatter(x=line_x, y=line_y, mode='lines',\n",
    "                                    line=dict(color='red', width=3, dash='dot'),\n",
    "                                    name='Primary Direction')\n",
    "fig.add_trace(primary_direction_line)\n",
    "\n",
    "# Right-align annotations for the regression line\n",
    "annotations = [dict(x=min(x), y=min(y)+4, xanchor='left', yanchor='bottom', \n",
    "                    showarrow=False, text='Regression to Mean',\n",
    "                    font=dict(color='blue'), bgcolor='white'),\n",
    "               dict(x=max(x), y=min(y), xanchor='right', yanchor='bottom', \n",
    "                    showarrow=False, text='\"Line of Best Fit\"<br>`trendline=\"ols\"`',\n",
    "                    font=dict(color='blue')),\n",
    "               dict(x=max(x), y=max(y)-4, xanchor='right', yanchor='bottom', \n",
    "                    showarrow=False, text='Major Axis', font=dict(color='red'))]\n",
    "\n",
    "# Add correlation annotation\n",
    "correlation = np.corrcoef(x, y)[0, 1]\n",
    "annotations.append(dict(x=min(x), y=max(y), xanchor='left', yanchor='top',\n",
    "                   showarrow=False, text=f'Correlation: {correlation:.2f}', \n",
    "                   font=dict(color='black'), bgcolor='white'))\n",
    "\n",
    "# Define your mx + b trendline formula\n",
    "# For example: y = 0.5x + 2\n",
    "# from scipy import stats\n",
    "# slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "m = 0.1616177526315975  # Slope\n",
    "b = 58.4194455765732    # Intercept\n",
    "trendline_x = np.array([55,79])\n",
    "trendline_y = b + m*np.array([55,79])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=trendline_x, y=trendline_y, mode='lines',\n",
    "                         line=dict(color='blue', width=2),\n",
    "                         name='yhat = 0.16 + 58.41x'))\n",
    "\n",
    "# Update layout with corrected annotations\n",
    "fig.update_layout(title=\"Galton's Midparent vs Child Height:<br>Regression to the mean IS NOT the Primary Direction\",\n",
    "                  xaxis_title=\"Child Height\", yaxis_title=\"Midparent Height\", annotations=annotations)\n",
    "\n",
    "# Set square aspect ratio for the axes\n",
    "fig.update_xaxes(scaleanchor=\"y\")  # X-axis is anchored to Y-axis\n",
    "fig.update_yaxes(constrain=\"domain\")  # Constrain the Y-axis to the domain of the plot\n",
    "#fig.update_xaxes(range=[55, 80])  # Fixed x limits\n",
    "fig.update_layout(height=400, width=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a29302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52771328/plotly-chart-not-showing-in-jupyter-notebook\n",
    "import plotly.offline as pyo\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c92bc1",
   "metadata": {},
   "source": [
    "### So this \"Regression to the mean\" is from dudess on left (while dudess on the right is Dar for the Win)\n",
    "\n",
    "More [Queens](https://www.youtube.com/watch?v=-tJYN-eG1zk) Supporting [Queens](https://www.youtube.com/watch?v=hFDcoX7s6rE) Serving Looks \n",
    "- Absolutely Fierce and Fabulous Boss Babe SLAY [Queens](https://www.youtube.com/watch?v=fJ9rUzIMcZQ)\n",
    "\n",
    "\n",
    "|Sir Francis Galton, alleged [child prodigy](https://www.youtube.com/watch?v=rmHDhAohJlQ), confirmed cousin to | Charles Darwin, all up [on the origin](https://en.wikipedia.org/wiki/On_the_Origin_of_Species) of [UrFavNewTerm](https://www.youtube.com/watch?v=JKWCVuWeK-8) \"Regression\" |\n",
    "|:-|-:|\n",
    "|![](https://upload.wikimedia.org/wikipedia/commons/e/ec/Francis_Galton_1850s.jpg)|![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Charles_Darwin_seated_crop.jpg/440px-Charles_Darwin_seated_crop.jpg)|\n",
    "|This man ^^^^^ INVENTED \"REGRESSION to the mean\" y'all|This man ^^^^^ appears -- as you can see from the figure above -- to be|\n",
    "| | EXTREMELEY ENVIOUS of the other man|\n",
    "| | HAHA I guess he just never did anything meaningful in his life HAHA what a loser| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b284607",
   "metadata": {},
   "source": [
    "### Correlation IS NOT Causation\n",
    "\n",
    "in the sense that there must OBVIOUSLY be other EASILY identifiable FACTORS at play\n",
    "\n",
    "### Does Height CAUSE weight?\n",
    "\n",
    "YOU tell ME\n",
    "\n",
    "### What IS Correlation anyway?\n",
    "\n",
    "**Well it's the following which you can try to make sense of later if you want to BUT WHO CARES FOR NOW**\n",
    "\n",
    "$\\LARGE r = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})}{(n-1) S_x S_Y}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\LARGE s_x = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}} \\quad \\text{and} \\quad s_Y = \\sqrt{\\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n - 1}}$\n",
    "\n",
    "so \n",
    "\n",
    "$\\LARGE r = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})}{\\sqrt{\\left( \\sum_{i=1}^n (x_i - \\bar{x})^2 \\right) \\left( \\sum_{i=1}^n (Y_i - \\bar{Y})^2 \\right)}}$ \n",
    "\n",
    "- $r$ = sample correlation coefficient\n",
    "- $n$ = number of paired observations\n",
    "- $x_i$ = value of the $i$-th observation of variable $x$\n",
    "- $Y_i$ = value of the $i$-th observation of variable $Y$\n",
    "- $\\bar{x}$ = mean of variable $x$\n",
    "- $\\bar{Y}$ = mean of variable $Y$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52206b33",
   "metadata": {},
   "source": [
    "### Correlation IS NOT Causation\n",
    "### Correlation JUST measures the Empirical Strength of a Linear Relationship\n",
    "- It doesn't tell you anything about WHY two things have an association with each other\n",
    "\n",
    "### But that's it: IT JUST TELLS US WHAT THE PICTURE LOOKS LIKE IN A SINGLE NUMBER (without $n$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "np.random.seed(10)\n",
    "n_points = 25\n",
    "ice_cream_sales = stats.uniform(10, 10).rvs(n_points)\n",
    "noise = np.random.normal(0, 2, n_points)\n",
    "shark_sightings = ice_cream_sales + noise\n",
    "data = pd.DataFrame({'Ice Cream Sales': ice_cream_sales,\n",
    "                     'Shark Sightings': shark_sightings})\n",
    "\n",
    "correlation = data['Ice Cream Sales'].corr(data['Shark Sightings'])\n",
    "\n",
    "fig = px.scatter(data, x='Ice Cream Sales', y='Shark Sightings', \n",
    "                 trendline='ols',  # Add a linear trendline\n",
    "                 trendline_color_override='red',\n",
    "                 title='Ice Cream Sales vs. Shark Sightings')\n",
    "\n",
    "fig.add_annotation(text=f'Correlation: {correlation:.2f}', \n",
    "                   xref='paper', yref='paper', \n",
    "                   x=0.05, y=0.95, showarrow=False,\n",
    "                   font=dict(size=12, color='black'), bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 934  # Number of points\n",
    "\n",
    "# Define means and standard deviations for midparent and child heights\n",
    "mean = [66, 64]  # Mean heights for midparent and child\n",
    "std_dev = [3, 3]  # Standard deviations for midparent and child\n",
    "correlation = 0.32\n",
    "\n",
    "# Create the covariance matrix\n",
    "covariance = np.array([[std_dev[0]**2, correlation * std_dev[0] * std_dev[1]],\n",
    "                       [correlation * std_dev[0] * std_dev[1], std_dev[1]**2]])\n",
    "\n",
    "# Generate bivariate normal data\n",
    "data = multivariate_normal(mean, covariance).rvs(n)\n",
    "galton_data = pd.DataFrame(data, columns=['Parent Mid Height', 'Child Height'])\n",
    "\n",
    "# Calculate the correlation\n",
    "correlation = galton_data['Parent Mid Height'].corr(galton_data['Child Height'])\n",
    "\n",
    "fig = px.scatter(galton_data, x='Child Height', y='Parent Mid Height', \n",
    "                 trendline='ols',  # Add a linear trendline\n",
    "                 trendline_color_override='red',\n",
    "                 title='Midparent vs Child Height with Trendline')\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.5))\n",
    "\n",
    "# Add correlation annotation\n",
    "fig.add_annotation(text=f'Correlation: {correlation:.2f}', \n",
    "                   xref='paper', yref='paper', \n",
    "                   x=0.05, y=0.95, showarrow=False,\n",
    "                   font=dict(size=12, color='black'), bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7e9a3",
   "metadata": {},
   "source": [
    "### Correlation IS NOT Causation\n",
    "### Correlation JUST measures the Empirical Strength of a Linear Relationship\n",
    "- It doesn't tell you anything about WHY two things have an association with each other\n",
    "\n",
    "### But that's it: it's the linear association pictured (without $n$) in a single number <u>AND/BUT you can BREAK IT</u>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Load Anscombe's quartet from Seaborn\n",
    "df = sns.load_dataset(\"anscombe\")\n",
    "\n",
    "# Function to calculate stats (correlation, mean, and std)\n",
    "def calculate_stats(subset):\n",
    "    correlation = np.corrcoef(subset['x'], subset['y'])[0, 1]\n",
    "    mean_x = subset['x'].mean()\n",
    "    mean_y = subset['y'].mean()\n",
    "    std_x = subset['x'].std()\n",
    "    std_y = subset['y'].std()\n",
    "    return correlation, mean_x, mean_y, std_x, std_y\n",
    "\n",
    "# Create a 2x2 subplot layout with Plotly\n",
    "fig = make_subplots(rows=2, cols=2, vertical_spacing=0.1, \n",
    "                    subplot_titles=[f\"Dataset {d}\" for d in df['dataset'].unique()])\n",
    "\n",
    "# Plot scatter and regression line for each dataset\n",
    "for i, dataset in enumerate(df['dataset'].unique()):\n",
    "    subset = df[df['dataset'] == dataset]\n",
    "    correlation, mean_x, mean_y, std_x, std_y = calculate_stats(subset)\n",
    "    row,col = (i // 2) + 1, (i % 2) + 1\n",
    "    \n",
    "    # Add scatter plot\n",
    "    fig.add_trace(go.Scatter(x=subset['x'], y=subset['y'],\n",
    "                  mode='markers', marker=dict(size=10), \n",
    "                  name=f\"Dataset {dataset}\"), row=row, col=col)\n",
    "    \n",
    "    # Add regression line\n",
    "    slope, intercept = np.polyfit(subset['x'], subset['y'], 1)\n",
    "    fig.add_trace(go.Scatter(x=subset['x'], y=slope * subset['x'] + intercept,\n",
    "                  mode='lines', name=f\"Fit {dataset}\",\n",
    "                  line=dict(color='red')), row=row, col=col)\n",
    "\n",
    "    # Add a separate trace for the annotation in the bottom right corner\n",
    "    stats_annotation = (f\"Corr: {correlation:.2f}<br>\"\n",
    "                        f\"Mean(x): {mean_x:.2f}<br>\"\n",
    "                        f\"Mean(y): {mean_y:.2f}<br>\"\n",
    "                        f\"Std(x): {std_x:.2f}<br>\"\n",
    "                        f\"Std(y): {std_y:.2f}\")\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=[max(subset['x']) - 1.2],  \n",
    "                             y=[min(subset['y']) + 1],  \n",
    "                             mode='text', text=[stats_annotation],\n",
    "                             showlegend=False), row=row, col=col)\n",
    "\n",
    "# Update layout to reduce space between rows\n",
    "fig.update_layout(height=600, width=800, title_text=\"Anscombe's Quartet with Correlation, Mean, and Std Dev\", \n",
    "                  margin=dict(l=50, r=50, t=50, b=50))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090631d0",
   "metadata": {},
   "source": [
    "### There are MANY kinds of associations (besides correlation) that are not actually LINEAR\n",
    "- And if you try to \"measure\" them with **THE LINEAR ASSOCIATION measure CORRELATION** you CAN FOR SURE get the wrong idea of \"what the picture looks like\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e04762",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "$$ \n",
    "\\Large\n",
    "\\begin{align}\n",
    "Y_i = {}& \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad \\text{ where } \\quad \\epsilon_i \\sim \\mathcal N\\left(0, \\sigma^2\\right)\\\\\n",
    "Y_i \\sim {}& \\mathcal N\\left( \\beta_0 + \\beta_1 x_i, \\sigma^2\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "- Outcome $Y_i$\n",
    "- Predictor $x_i$\n",
    "- Intercept $\\beta_0$ coefficient\n",
    "- Slope $\\beta_1$ coefficient\n",
    "- Error term $\\epsilon_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 25\n",
    "\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\n",
    "\n",
    "# Calculate the correlation\n",
    "correlation = np.corrcoef(df['x'], df['Y'])[0,1]\n",
    "\n",
    "fig = px.scatter(df, x='x', y='Y', \n",
    "                 trendline='ols',  # Add a linear trendline\n",
    "                 trendline_color_override='red',\n",
    "                 title='Y vs x')\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.5))\n",
    "\n",
    "fig.add_annotation(text=f'Correlation: {correlation:.2f}', \n",
    "                   xref='paper', yref='paper', \n",
    "                   x=0.05, y=0.95, showarrow=False,\n",
    "                   font=dict(size=12, color='black'), bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaab25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stats.uniform(10, 10).rvs(n_points)\n",
    "Y = 0 + x + stats.norm(loc=0, scale=10).rvs(size=n)\n",
    "\n",
    "n = 934\n",
    "x = galton_data['Parent Mid Height']\n",
    "# x = stats.norm(loc=x.mean(), scale=x.std()).rvs(size=n)\n",
    "beta0 = -100 # galton_data['Child Height'].mean()\n",
    "beta1 = 2\n",
    "Y = beta0 + beta1*x + stats.norm(loc=0, scale=3).rvs(size=n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd3ddc",
   "metadata": {},
   "source": [
    "# The Homework this time around is VERY DIFFERENT\n",
    "### It's VERY LONG. It's VERY, VERY DEMANDING. You will do/understand COMPLICATED SIMULATIONS\n",
    "### You don't turn it in until AFTER you get back from READING WEEK (Thursday before TUT as usual)\n",
    "### Your Project Proposals ARE DUE ON MONDAY IMMEDIATELY UPON RETURN FROM READING WEEK\n",
    "\n",
    "- The HW is longer since there's substantially more time to do it\n",
    "- However, I still need to finalize the HW and make the rubric, which \n",
    "    - I expect to do tomorrow, Tuesday Oct 22.\n",
    "    - My apologies for not being quite ready this time around\n",
    "    - And similarly, the textbook for linear regression has not yet been finalized \n",
    "        - but I will do so ASAP, ideally by tomorrow-tomorrow, Wednesday Oct 22.\n",
    "- A draft of the \"Course Project Proposals\" assignment is available in the CP folder on the course github\n",
    "    - This is due on Monday, Nov 04 the day you return from your reading week\n",
    "    - I will alert the class with an announcement when the final I need to \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
