{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STA130 TUT 05 (Oct04)<br><br>ü§î‚ùì <u>\"Single Sample\" Hypothesis Testing<u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ‚ôªÔ∏è üìö Review  / Questions [15 minutes]\n",
    "\n",
    "1. Follow up questions and clarifications regarding **bootstrapping, sampling distributions**, and **confidence intervals**\n",
    " \n",
    "   > such as how to use the **sampling distribution of sample mean** of the $\\bar x$ **sample statistic** is used to provide **estimation / statistics inference** regarding the corresponding **population parameter** Œº...\n",
    "   > \n",
    "   > *...or address a* **null hypothesis** *about* Œº</u>\n",
    "\n",
    "      <details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>  \n",
    "    \n",
    "      > Sep27 TUT and Sep30 LEC of the previous week addressed **bootsrapped confidence intervals** and breifly introduced the notion of using the **variability/uncertainty** of the **samping distribution** of a **sample statistic** (driven by the **sample size** $n$) to evaluate a **null hypothesis** about a corresponding **population parameter** \n",
    "      >\n",
    "      > This week builds on this concept and formally introduces **hypothesis testing** with **null** and **alternative hypotheses**, which will be much easier to understand if the concept and purpose of a **samping distribution** and **confidence intervals** is well understood...\n",
    "\n",
    "\n",
    "### üöß üèóÔ∏è Demo I (introducing formal Hypothesis Testing) [15 minutes]\n",
    "\n",
    "> The scientific method is most fundamentally the process of providing evidence against the current views. You have to provide evidence against old views in order to reject the old hypotheses before you can move on to a new paradigm.\n",
    "\n",
    "\n",
    "|<img src=\"https://pictures.abebooks.com/inventory/md/md31377899338.jpg\" alt=\"Scientific Revolusions\" style=\"width: 300px; height: 450px;\"/>|<img src=\"https://i.ytimg.com/vi/Yn8cCDtVd5w/maxresdefault.jpg\" alt=\"Kuhn Cycle\" style=\"width: 800px; height: 450px;\"/>|\n",
    "|-|-|\n",
    "| | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's return to the \" [Project: Vaccine Data](https://github.com/pointOfive/stat130chat130/blob/main/HW/STA130F24_HW04_DueOct03.ipynb) \" [last week's (week 4) HW Question \"8\"]\n",
    "\n",
    "- We'll review the goal of the project and introduce the simulation based appproach that would address null hypothesis aspect of the project in a formal hypothesis testing manner based on confidence intervals \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "patient_data = pd.DataFrame({\n",
    "    \"PatientID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"Age\": [45, 34, 29, 52, 37, 41, 33, 48, 26, 39],\n",
    "    \"Gender\": [\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
    "    \"InitialHealthScore\": [84, 78, 83, 81, 81, 80, 79, 85, 76, 83],\n",
    "    \"FinalHealthScore\": [86, 86, 80, 86, 84, 86, 86, 82, 83, 84]\n",
    "})\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First let's format this data in the manner of last week's HW \"Prelecture\" video\n",
    "# from IPython.display import YouTubeVideo\n",
    "# YouTubeVideo('Xz0x-8-cgaQ', width=800, height=500)  # https://www.youtube.com/watch?v=Xz0x-8-cgaQ\n",
    "\n",
    "patient_data['HealthScoreChange'] = patient_data.FinalHealthScore-patient_data.InitialHealthScore\n",
    "# why do we do the subtraction in this order?\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### The <u>Null Hypothesis</u> [and Alternative Hypothesis]\n",
    "\n",
    "The **null hypothesis** usually simply states the \"no effect\" (on average) assumption\n",
    "\n",
    "$\\Large H_0: \\text{The vaccine has no effect }\\textbf{[on average]}\\text{ on patient health}\\\\\n",
    "\\Large H_1: H_0 \\text{ is false}$\n",
    "\n",
    "To empasize that \"**[on average]**\" refers to the pupulation parameter $\\mu$ (the average difference of the effect), it is helpful to more formally (and concisely) express this equivalently as \n",
    "\n",
    "$$\\Large H_0: \\mu=0 \\quad \\text{ and } \\quad H_A: H_0 \\text{ is false}$$\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "As introduced in the \"Further Guidance\" to last weeks (Week 4) HW Question \"7\"...\n",
    "\n",
    "> \"...**null hypotheses** proceeds on the basis of the **scientific method**; meaning, it's what we beleive until we have sufficient evidence to no longer believe it. As such, the **null hypotheses** is typically something that we **do not** actually believe; and, actually, the **null hypotheses** simply serves as a sort of \"straw man\" which we in fact really intend to give evidence against so as to no longer believe it.\"\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Even Further Guidance</u></summary>    \n",
    "\n",
    "#### Some \"hidden\" assumptions...\n",
    "Differences in the \"before and after\" `HealthScore` could be due to a lot of factors; but, if the only thing we did as an intervention was giving the patients the vaccine treatment, then we would expect the other factors to be a wash over time and just kind of average out... right?\n",
    "- Do we think something else could happen that would tend to generally increase everyone's health score after the initial measurement (besides our intervention)? \n",
    "    - If so, this would be called a **confounder**... otherwise we're saying we have \"**no confounding**\"\n",
    "- Do we think we have a large enough sample size for \"other factors\" to \"average out\"? \n",
    "    - Usually we consider increased sample size from the perspective of reducing standard error to reduce estimation uncertainty; but, this consideration suggests we should also be concerned with sample size from the perspective of \"averaging out\" **confounding imbalances**...\n",
    "</details>\n",
    "\n",
    "\n",
    "#### Now let's demonstrate formal hypothesis testing using simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Evidence against null hypothesis using confidence intervals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Bootstrapping\n",
    "# np.random.seed(130)  # make simulation reproducible\n",
    "number_of_simulations = 1000 \n",
    "n_size = len(patient_data)  # 10\n",
    "bootstrap_means = np.zeros(1000)  # array to store bootstrapped means\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    \n",
    "    # bootstrap sample size is the same (\"apples to apples\") as the original sample size\n",
    "    sample = patient_data.sample(n=n_size, replace=True)  # `replace=True`!!\n",
    "    bootstrap_means[i] = sample['HealthScoreChange'].mean()  # bootstrapped mean\n",
    "\n",
    "# Calculating the 95% confidence interval\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why and with what \"confidence\" do we reject $H_0$ based on the interval above?\n",
    "\n",
    "- *Hint: the figure below shows the distribution of bootstrapped means which are the \"plausible average Health Score Change\" (for the given sample size, insofar as the sample is representative of the population...); so, \"0\" means \"no effect on average\"...*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/52771328/plotly-chart-not-showing-in-jupyter-notebook\n",
    "import plotly.offline as pyo\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure for demonstration only: code details not of primary concern\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "hist_data = [bootstrap_means]\n",
    "group_labels = ['Bootstrapped<br>Sampling Distribution<br>of the Sample Mean']\n",
    "fig = ff.create_distplot(hist_data, group_labels, \n",
    "                         show_hist=True, show_rug=False, bin_size=0.4)\n",
    "\n",
    "# Add a line for the lower confidence interval\n",
    "ci_y = 0.35  # Adjust height as needed\n",
    "fig.add_shape(type=\"line\", x0=ci_lower, y0=0, x1=ci_lower, y1=ci_y,\n",
    "              line=dict(color=\"Red\", width=2), name=\"95% CI Lower\")\n",
    "# Add a line for the upper confidence interval\n",
    "fig.add_shape(type=\"line\", x0=ci_upper, y0=0, x1=ci_upper, y1=ci_y,\n",
    "              line=dict(color=\"Red\", width=2), name=\"95% CI Upper\")\n",
    "# Add a transparent rectangle for the confidence interval region\n",
    "fig.add_shape(type=\"rect\", x0=ci_lower, y0=0, x1=ci_upper, y1=ci_y,\n",
    "    fillcolor=\"LightSkyBlue\", opacity=0.5, line_width=0)\n",
    "# Add annotations for the confidence interval lines\n",
    "fig.add_trace(go.Scatter(x=[ci_lower, ci_upper], y=[ci_y+0.01, ci_y+0.01],  \n",
    "              text=[\"95% CI Lower\", \"95% CI Upper\"], mode=\"text\", showlegend=False))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Bootstrapped Sampling Distribution with 95% Confidence Interval\",\n",
    "    xaxis_title=\"Mean Health Score Change\", yaxis_title=\"Density\")\n",
    "fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üî® üí™üèº Demo II (of Hypothesis Testing using p-values) [30 minutes]<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "The above illustrates rejecting a null hypothesis $H_0$ on the basis of a 95% bootstrapped confidence interval (with 95% confidence) since the 95% confidence interval \"does not cover 0\"\n",
    "\n",
    "- This is an ideal way to address hypothesis testing, but it's (unfortunately)  also quite common to give \"evidence against\" a null hypothesis in the form of a p-value\n",
    "</details>\n",
    "         \n",
    "A **p-value** is **the probability that a test statistic is as or more extreme than the observed test statistic if the null hypothesis is true**\n",
    " \n",
    "> To understand what the definition of a **p-value** means, let's consider the definition in reverse \n",
    "> \n",
    "> 1. What is the meaning of \"if the null hypothesis was true\"?\n",
    "> 2. What is the meaning of \"test statistic is as or more extreme than the observed test statistic\"? \n",
    "> 3. What is the meaning of \"the probability that a test statistic is...\"?\n",
    "\n",
    "#### 1. \"if the null hypothesis is true\"...\n",
    "\n",
    "> $$H_0: \\text{The vaccine has no effect }\\textbf{[on average]}\\text{ on patient health}$$\n",
    "> \n",
    "> implies that improvements or reductions between `FinalHealthScore` and `InitialHealthScore` are actually really just \"random\"\n",
    ">\n",
    "> - so we could just simulate sampling distribution of the \"proportion of cases that improved\" under the assumption of the null hypothesis that the signs of the differences between `InitialHealthScore` and `FinalHealthScore` is actually really just as random as the process of flipping a fair coin...\n",
    ">\n",
    "> We'll therefore use the following slightly different version null hypothesis\n",
    "> \n",
    "> $$H_0: \\text{The chance the vaccine improves patient health} \\textbf{ is 50%}$$\n",
    ">\n",
    "> <details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "> \n",
    "> We're changing $H_0$ for two reasons; first, this is the version that we want to introduce and construct the foundation of hypothesis testing with; and, second, for a \"technical\" reason this null hypothesis is also more amenable to the simulation approaches that we're leveraging in STA130. \n",
    "> - Something for advanced students to consider would be, \"How could bootstrapping be applied to this null hypothesis (instead of the original null hypothesis)?\"\n",
    "> </details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you get the idea here?\n",
    "\n",
    "print(pd.DataFrame({'HealthScoreChange': patient_data['HealthScoreChange'],\n",
    "                    '> 0 ?': patient_data['HealthScoreChange']>0}))\n",
    "\n",
    "random_difference_sign = np.random.choice([-1, 1], size=len(patient_data))\n",
    "pd.DataFrame({'HealthScoreChange': random_difference_sign*patient_data['HealthScoreChange'].abs(),\n",
    "              '> 0 ?': (random_difference_sign*patient_data['HealthScoreChange'])>0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#np.random.seed(130)  # make simulation reproducible\n",
    "number_of_simulations = 10000  # experiment with this... what does this do?\n",
    "n_size = len(patient_data)  # 10\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "# generate \"random improvement\" proportions assuming H0 (vaccine has no average effect) is true \n",
    "# meaning that the \"before and after\" differences are positive or negative at \"random\"\n",
    "for i in range(number_of_simulations):\n",
    "    \n",
    "    # why is this equivalent to the suggested idea above?\n",
    "    random_improvement = np.random.choice([0,1], size=len(patient_data), replace=True)  # <<< `replace=True` ^^^\n",
    "\n",
    "    # why is .mean() a proportion? \n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "    # why is this the statistic we're interested in? Hint: next section..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. \"test statistic is as or more extreme than the observed test statistic\"...\n",
    "\n",
    "> To understand \"as or more extreme\" we first need to consider $H_0$ formally in terms of the hypothesized population parameter \n",
    "> \n",
    "> \\begin{align*}\n",
    "H_0: p=0.5 \\quad &{} \\text{instead of the equivalent} \\\\\n",
    "&{} H_0: \\text{The chance the vaccine improves patient health} \\textbf{ is 50%}\n",
    "\\end{align*}\n",
    "> \n",
    "> This is because \"as or more extreme\" is relative to a hypothesized population parameter which the test statistic estimates\n",
    "> - Then, we need to clearly differentiate and compare the \"simulated test statistcs\" from the \"observed test statistic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"as or more extreme\" relative to the hypothesized parameter of the test statistic!\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "observed_test_statistic = (patient_data.HealthScoreChange>0).mean()\n",
    "simulated_test_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "SimTestStats_as_or_more_extreme_than_ObsTestStat = \\\n",
    "    abs(simulated_test_statistics - population_parameter_value_under_H0) >= \\\n",
    "    abs(observed_test_statistic - population_parameter_value_under_H0) \n",
    "    \n",
    "print('''Which simulated test statistics are \"as or more extreme\"\n",
    "than the observed test statistic? (of ''', observed_test_statistic, ')', sep=\"\")\n",
    "\n",
    "pd.DataFrame({'(Simulated) Test Statistic': simulated_test_statistics,\n",
    "              '>= '+str(observed_test_statistic)+\" ?\": ['>= '+str(observed_test_statistic)+\" ?\"]*number_of_simulations, \n",
    "              '\"as or more extreme\"?': SimTestStats_as_or_more_extreme_than_ObsTestStat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure for demonstration only: code details not of primary concern\n",
    "\n",
    "hist_data = [IncreaseProportionSimulations_underH0random+np.random.uniform(-0.05,0.05,size=len(IncreaseProportionSimulations_underH0random))]\n",
    "group_labels = ['Bootstrapped Sampling Distribution<br>of the Sample Mean<br><br>under the assumption that<br>the null hypothesis H0 IS TRUE']\n",
    "fig = ff.create_distplot(hist_data, group_labels, curve_type='normal',\n",
    "                         show_hist=True, show_rug=False, bin_size=0.1)\n",
    "\n",
    "pv_y = 2.5\n",
    "pv_y_ = .25\n",
    "fig.add_shape(type=\"line\", x0=observed_test_statistic, y0=0, \n",
    "              x1=observed_test_statistic, y1=pv_y,\n",
    "              line=dict(color=\"Green\", width=4), name=\"Observed Test Statistic\")\n",
    "fig.add_trace(go.Scatter(x=[observed_test_statistic], y=[pv_y+pv_y_], \n",
    "                         text=[\"Observed<br>Test Statistic<br>^\"], mode=\"text\", showlegend=False))\n",
    "# \"as or more extreme\" also include the \"symmetric\" observed test statistic...\n",
    "symmetric_test_statistic = population_parameter_value_under_H0 -\\\n",
    "                           abs(observed_test_statistic-population_parameter_value_under_H0)\n",
    "fig.add_shape(type=\"line\", x0=symmetric_test_statistic, y0=0, \n",
    "              x1=symmetric_test_statistic, y1=pv_y,\n",
    "              line=dict(color=\"Green\", width=4), name=\"Observed Test Statistic\")\n",
    "fig.add_trace(go.Scatter(x=[symmetric_test_statistic], y=[pv_y+pv_y_], \n",
    "                         text=['\"Symmetric\" Observed Test Statistic<br>addrdssing for \"as or more extreme\"<br>^'], mode=\"text\", showlegend=False))\n",
    "\n",
    "# Add a transparent rectangle for the lower extreme region\n",
    "fig.add_shape(type=\"rect\", x0=-0.15, y0=0, x1=symmetric_test_statistic, y1=pv_y,\n",
    "              fillcolor=\"LightCoral\", opacity=0.5, line_width=0)\n",
    "# Add a transparent rectangle for the upper extreme region\n",
    "fig.add_shape(type=\"rect\", x0=observed_test_statistic, y0=0, x1=1.15, y1=pv_y,\n",
    "              fillcolor=\"LightCoral\", opacity=0.5, line_width=0)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Bootstrapped Sampling Distribution under H0 with p-value regions\",\n",
    "    xaxis_title=\"Mean Health Score Change\", yaxis_title=\"Density\", yaxis=dict(range=[0, pv_y+2*pv_y_]))\n",
    "fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Clarification Questions\n",
    "> 1. What is the difference in the \"middle value\" of<br>\"the bootstrapped sampling distribution of the sample mean\" VERSUS<br>\"the bootstrapped sampling distribution of the sample mean under the (assumption of) null hypothesis?\"<br><br>\n",
    ">\n",
    "> 2. What's the difference between the \"interval\" for bootstrapped confidence intervals compared to the \"as ore more extreme\" regions which p-values are based on? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. \"the probability that a test statistic is...\"<br> [\"as or more extreme\" than the observed test statistic]<br> (if the null hypothesis is true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "# How many bootstrapped statistics generated under H0 \n",
    "# are \"as or more extreme\" than the observed statistic \n",
    "# (relative to the hypothesized population parameter)? \n",
    "\n",
    "observed_test_statistic = (patient_data.HealthScoreChange>0).mean()\n",
    "simulated_test_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "# Be careful with \"as or more extreme\" as it's symmetric!\n",
    "SimTestStats_as_or_more_extreme_than_ObsTestStat = \\\n",
    "    abs(simulated_test_statistics - population_parameter_value_under_H0) >= \\\n",
    "    abs(observed_test_statistic - population_parameter_value_under_H0)\n",
    "    \n",
    "p_value = (SimTestStats_as_or_more_extreme_than_ObsTestStat).sum() / number_of_simulations\n",
    "print(\"Number of Simulations: \", number_of_simulations, \"\\n\\n\",\n",
    "      \"Number of simulated test statistics (under HO)\\n\",\n",
    "      'that are \"as or more extreme\" than the observed test statistic: ',\n",
    "      SimTestStats_as_or_more_extreme_than_ObsTestStat.sum(), \"\\n\\n\",\n",
    "      'p-value (= simulations \"as or more extreme\" / total simulations): ', p_value, sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But does a p-value mean?\n",
    "\n",
    "This is easy: the smaller the p-value, the stronger the evidence against the null hypothesis\n",
    "\n",
    "#### Wait, but why? \n",
    "\n",
    "A **p-value** is \"the probability that a test statistic is as or more extreme than the observed test statistic if the null hypothesis is true\"\n",
    "- So if the **p-value** is small, then the observed test statistic is very strange relative to the null hypothesis\n",
    "- This means the data is very unusual if the null hypothesis is true, so it's probably more likely that the null hypothesis is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí¨ üó£Ô∏è Communication Activity<br>üé≤ üÉè Stella McStat's Wheel of Destiny  [40 minutes]\n",
    "\n",
    "**[~3 of the 40 minutes]** Break into 5 new groups of 4-5, assigning each group to one of the questions. \n",
    "\n",
    "**[~12 of the 40 minutes]** Review and discuss the questions within the group. \n",
    "\n",
    "**[~25 of the 40 minutes / 5 minutes per group]** As soon as a group (in order) is ready **[even before 12 minutes are up]**, they should immediately **introduce their general topic and questions** and discuss their answers with the class; each group should build on the answers of the previous group **[perhaps requesting additional time to do so if the initial 12 minutes or review and discussion have not yet been used up]**, with the previous groups ensuring that the next groups are indeed taking advantage of the foundation their answers and discussions have provided.\n",
    "\n",
    "> This is expected to be a dynamic sequentially dependent process (not independent sampes!) in which all groups should work together by contributing their part in order to complete the overall process within 40 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### The Wheel of Destiny\n",
    "\n",
    "Stella McStat had been running a small-time gambling operation on campus for several months during her first year at UofT... \n",
    "\n",
    "- For each spin of the wheel, two gamblers take part. For a toonie each (\\\\$2 Canadian), Stella sells one a red ticket and one a black ticket  (i.e., total \\\\$4). Then Stella spins the Wheel of Destiny. The person who holds the colour on which the spinner stops gets \\\\$3.50 (Stella keeps \\\\$0.50 per spin for running the game and providing snacks).\n",
    "\n",
    "Stella just bought a new spinner, the critical piece of equipment for this game. She's heard some mixed reviews about the manufacturer she has purchased from. Before she beings using this spinner, she wants to make sure that it is, in fact, fair (meaning, she wants both colours to come up equally often). Because of the set-up of the game, Stella has no incentive to cheat and wants the game to be as fair as possible.\n",
    "\n",
    "Everything phystical and mechanical that Stella can examine about the wheel seems fine; there is the same number of sectors of each colour and they each have the same area. BUT! Stella has a great idea and decides to come to YOU, her statistical guru, and ask you to verify that the new spinner is fit to use. Is Stella's game is \"fair\" (even if somewhat illegal)?\n",
    "\n",
    "\n",
    "| <img src=\"https://i.postimg.cc/BvqJwBwc/stella2.png\" style=\"height: 450px;\"/> |  <img src=\"https://i.postimg.cc/vm3GRxJR/fair.png\" style=\"height: 450px;\"/> |\n",
    "|-|-|\n",
    "|An Exercise for Illustrating the Logic of Hypothesis Testing|Adapted from Lawton, L. (2009), Journal of Stat. Education, 17(2)|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. What's \"data\" here?<br><br>\n",
    "    1. What is a **sample** here? Hint: the **population** would be every spin result ever \n",
    "    2. Do you think spins comprising a sample are **dependent** or **independent**?\n",
    "    3. What is the difference between a **parameter** and a **statistic**?<br><br>\n",
    "\n",
    "2. How could we create a **confidence interval** to estimate the proportion of times spins land on red?<br><br>\n",
    "    1. What statistic should the **confidence interval** be based on?\n",
    "    2. What exactly would the process be to create a **confidence interval**? Would it be based on **bootstrapping**? Would is there another form of repeated \"simulation\"(?) that could be used?\n",
    "    3. Besides changing the **confidence level** (e.g., from 95% to 90%), how else could we make the confidence interval narrower (and why is this preferrable)?<br><br> \n",
    "\n",
    "3. How can we examine the wheel for fairness from a statistical perspective?<br><br>\n",
    "    1. What is the difference between a **null hypothesis** and an **alternative hypothesis**? \n",
    "    2. What are the **null** and **alternative hypotheses** here?     \n",
    "    3. How could you use a **confidence interval** to make a decision about a **null hypothesis** that the wheel is fair?<br><br>\n",
    "\n",
    "4. How could we simulate the sampling distribution of the proportion of times spins land on red for a hypothetically fair wheel (as opposed to the wheel Stella actually has)?<br><br>\n",
    "    1. How could you simulate the data needed to create the **sampling distribution**?\n",
    "    2. What **statistic** should the **sampling distribution** be based on, and what should the sample size be for the samples on which the **sampling distribution** is built?\n",
    "    3. How is the proces different than the process for creating a **confidence interval** (from questions 2)?<br><br>\n",
    "    \n",
    "5. How could we provide a **p-value** for a **null hypothesis** of \"fairness\"?<br><br>\n",
    "    1. What is the definition of a **p-value**?\n",
    "    2. What is the process of using simulation to calculate a p-value for this problem?\n",
    "    3. How would you interpret a p-value you obtained through this process in terms of the evidence it potentially provides against the null hypothesis? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
