{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da914c6",
   "metadata": {},
   "source": [
    "# STA130 TUT 01 (Sep06)<br> <u> Hitting the ground running... <u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8969b8",
   "metadata": {},
   "source": [
    "\n",
    "## (Using notebooks and ChatBots) Demo [35 minutes]\n",
    "\n",
    "1. **[About 5 of the 35 minutes]** Demonstrate accessing the [Course GitHub Repo](https://github.com/pointOfive/STA130_ChatGPT) from Quercus; opening a notebook in [UofT Jupyterhub](https://datatools.utoronto.ca) [or google collab](https://colab.research.google.com/); and using Jupyter Notebooks as a \"`Python` calculator\"\n",
    "\n",
    "\n",
    "2. **[About 5 of the 35 minutes]** Demonstrate Jupyter Notebooks as a [\"Markdown editor\"](http://markdownguide.org)\n",
    "\n",
    "\n",
    "3. **[About 15 of the 35 minutes]** Demonstrate using [Copilot](https://copilot.microsoft.com/) [or [ChatGPT](https://chat.openai.com/)] for \n",
    "    1. finding an amusing, funny, or otherwise interesting dataset which has missing values and is available online through a URL link to a csv file; and, then\n",
    "    2. loading the data into the notebook with `pandas` and getting \"missing data counts\" for the dataset\n",
    "\n",
    "> The objective here is to see if the ChatBot can fullfil the parameters of the request, so the expercise is to confirm that the requirements (of working url links, a \"funny or amusing\" nature, and the presence of missingness) are met \n",
    ">\n",
    "> Two ends of the ChatBot prompting spectrum are\n",
    "> 1. creating an extensive prompt exhuastively specifying the desired response results; or, \n",
    "> 2. iteratively clarifying the the desired response results through interactive ChatBot dialogue\n",
    "> \n",
    "> *but a single demonstration of either will be sufficiently informative for now...* \n",
    ">\n",
    "> > This can either [go well](../CHATLOG/SLS/COP/00006_copilot_funnyamusingNAdataset.md) or [go poorly](../CHATLOG/SLS/COP/00002_copilot_funnyamusingNAdataset.md), *but a single demonstration of either will be sufficiently informative for now* \n",
    "> > - The positive example above used \"creative\" mode while the poor example above used \"precise\" mode; however, this likely has more to do with the nature of the prompting and engagement as the actual type of bot being used... for example, \"precise\" mode [here](../CHATLOG/SLS/COP/00007_copilot_funnyamusingNAdatasetV4.md) worked well...\n",
    "> > - ChatGPT3.5 can similarly result in \n",
    "> > [productive (useful)](../CHATLOG/SLS/GPT/00001_gpt3p5_villagersdata.md)\n",
    "> > and [unproductive (frustrating and annoying)](../CHATLOG/SLS/GPT/00002_gpt3p5_funnyasusingNAdataset.md) sessions\n",
    "\n",
    "<!-- \n",
    "> - **Topics of filling or imputing missing values and assumptions therein are \"out of scope\" for STA130**\n",
    "-->\n",
    " \n",
    "> ChatBots don't seem to be very aware of the contents of datasets that are avalable online (or even working url links where datasets are); so, ChatBot don't seem to be a substitue for exploring dataset repository such as [TidyTuesday](https://github.com/rfordatascience/tidytuesday) (or other data repositiory resources) and reviewing data yourself; but, ChatBot interactions nonetheless can help brainstorm dataset ideas and provide a way to \"search for content\" (perhaps with reference to a specific website)\n",
    ">\n",
    "> ChatBots have a notoriously \"short term memory\"; so, be ready for them to \"forget\" specific details of your prompting requests from time to time...\n",
    "\n",
    "\n",
    "4. **[About 5 of the 35 minutes]** Demonstrate prompting the ChatBot to \n",
    "    1. \"Please provide a summary of our interaction for submitting as part of the requirements of a assignment\"; and, to \n",
    "    2. \"Please provide me with the final working verson of the code that we created\" \n",
    "    \n",
    "> Share these with the students through a piazza post and a Quercus announcement so they can use this later for their homework assignment if they wish\n",
    "\n",
    "\n",
    "5. **[About 5 of the 35 minutes]** Demonstrate saving your python jupyter notebook in your own account and \"repo\" on [github.com](github.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379538b1",
   "metadata": {},
   "source": [
    "## Communication [65 minutes]\n",
    "        \n",
    "1. In 8 groups of 3, or thereabouts...\n",
    "    1. **[About 15 of the 65 minutes]** Ice breakers / introductions\n",
    "        1. Each person may bring two emojis to a desert island... reveal your emojis at the same time... for emojis selected more than once the group should select one additional emoji\n",
    "        2. Where are you from, what do you think your major might be, and what's an \"interesting\" fact that you're willing to share about yourself?\n",
    "        \n",
    "    2. **[About 10 of the 65 minutes]** These are where all the bullet holes were in the planes that returned home so far after some missions in World War II\n",
    "        1. Where would you like to add armour to planes for future missions?\n",
    "        2. Hint: there is a hypothetical dataset of the bullet holes on the planes that didn't return which is what we'd ideally compare the dataset we observe to...\n",
    "        \n",
    "           ![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Survivorship-bias.svg/640px-Survivorship-bias.svg.png)\n",
    "           \n",
    "    3. **[About 10 of the 65 minutes]** Monte Hall problem: there are three doors, one of which has a prize, and you select one and the gameshow host reveal one of the other two doors to not have the prize... would you like to change your guess to the other unknown door?\n",
    "\n",
    "       ![](https://mathematicalmysteries.org/wp-content/uploads/2021/12/04615-0sxvwbnzvvnhuklug.png) \n",
    "    \n",
    "4. **[About 30 of the 65 minutes]** Review the experience of the groups for the WW2 planes and Monte Hall problems\n",
    "    1. For each of these problems, have students vote on whether their groups (a) agreed on answers from the beginning, (b) agreed only after some discussion and convincing, or (c) retained somewhat divided in their opinions of the best way to proceed\n",
    "    2. Briefely discuss a few of the general answers the groups arrived at\n",
    "    3. Prompt a [Copilot](https://copilot.microsoft.com/) [or [ChatGPT](https://chat.openai.com/)] ChatBot to introduce and explain \"survivorship bias\" using spotify songs as an example (like [this](../CHATLOG/SLS/COP/00009_copilot_survivorshipbias_spotify.md) or [this](../CHATLOG/SLS/GPT/00003_gpt3p5_spotify_Survivorship_Bias.md) or you could instead try to approach things more generally like [this](../CHATLOG/SLS/COP/00008_copilot_survivorshipbiasgeneral.md) or [this](../CHATLOG/SLS/GPT/00004_gpt3p5_general_Survivorship_Bias.md)) and see if students are able to generalize this idea for the WW2 planes problem and if they find it to be a convincing argument to understand the problem\n",
    "    4. Prompt a [Copilot](https://copilot.microsoft.com/) [or [ChatGPT](https://chat.openai.com/)] ChatBot to introduce and explain the Monte Hall problem and see if the students find it understandable and convincing\n",
    "        1. Very briefly show the following transcript logs where the ChatBot fails when it's pushed to explain the problem using a formal probabilistic argument... [ChatGPT3.5 fails by wrongly calculating a probability of 1/2](../CHATLOG/SLS/GPT/00005_gpt3p5_MonteHallWrong.md), while [Copilot on \"creative\" mode honestly doesn't fair much better without substantial guidance...](../CHATLOG/SLS/COP/00010_copilot_montehallwrong.md )... \n",
    "            1. **Both of these examples go to show the that there are clear limits to how deeply ChatBots are able to \"reason\" which of course is a result of the fact that the information they base their regurgitations can lead to a \"garbage in, garbage out\" situation...**\n",
    "\n",
    "        2. Discuss how the nature of prompting and follow up questions influences the nature of the conversation and the degree to which the discussion can be directed and extended "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad910f",
   "metadata": {},
   "source": [
    "## Homework [0 minutes]\n",
    "\n",
    "Code and write all your answers (for both the \"Prelecture\" and \"Postlecture\" HW) in a python notebook (in code and markdown cells) and paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook.\n",
    "\n",
    "> You can create summaries of your ChatBot sessions by using concluding prompts such as\n",
    "> 1. \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\"; and, \n",
    "> 2. \"Please provide me with the final working verson of the code that we created together\".\n",
    "\n",
    "Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking. \n",
    "\n",
    "> A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "> Indeed, STA130 Homework essentially boils down to completing various understanding confirmation demonstration exercises oriented around coding and writing tasks.\n",
    "> However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    ">\n",
    "> > Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    ">\n",
    "> It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.\n",
    "> \n",
    "> #### Prompt Engineering? \n",
    ">\n",
    "> The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "> 1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "> 2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    ">\n",
    "> In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)... the thing is, you'll like it better if you do it to copilog before copilot does it to you ;)\n",
    "\n",
    "\n",
    "\n",
    "#### *The marking rubic (which may award partial credit) is as follows:*\n",
    "\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.2 points]: Reasonable general definitions for \"2.B\"\n",
    "- [0.2 points]: Demonstrated understanding regarding \"4\"\n",
    "- [0.2 points]: A sensible justification for the choice in \"7.D\"\n",
    "- [0.3 points]: Requested assessment of ChatBot versus google performance in \"8\"\n",
    "\n",
    "\n",
    "> The \"Ethical Profesionalism\" and \"Course Project\" sections below **are not a part of the submitted homework**; however, they will be a regularly available re-occuring weekly series guiding you through (a) relevant considerations regarding proper professional and ethical conduct, and (b) demonstrating the steps of large data analyses as illustrated through the example of the the STA130 course project, <u>both of which will likely be of interest and useful if they are consistently engaged with over the course of the semester.</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778909e",
   "metadata": {},
   "source": [
    "### *Scope Constraints and Relevant Resources*\n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/STA130_ChatGPT/wiki) for the list of topics covered in this homework assignment; and, **importantly**, a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment and hence can be safely ignored while working through the homework assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8cc949",
   "metadata": {},
   "source": [
    "\n",
    "### Prelecture HW\n",
    "\n",
    "1. Pick one of the datasets from your **TUT demo** (or from one of the many example demos linked above or your own version of the ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data confirm that the dataset has missing values\n",
    "\n",
    "```python\n",
    "# For example you could use the following...\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n",
    "```\n",
    "\n",
    "2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to understand how many columns of data you have, and how many rows of data you have\n",
    "    > Something like, \"I've downloaded a dataset about characters from animal crossings (from https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv), and I'd like to know what columns of information I have and how much data I have\" would be a good initial prompt to start with\n",
    "    > - You may need to quickly follow this up with \"I've already downloaded the data and want to understand the size (or dimensions) of the dataset to start with.\"\n",
    "    >     - Some ChatBots (like ChatGPT) will try suggesting that you to upload your data, but if you do so [they will likely end your session without providing any analysis unless you purchase an upgrade](../CHATLOG/SLS/GPT/00006_gpt3p6_LoadDataPaywall.md) \n",
    "    >       > **You DO NOT need to purchase an upgraded version of any ChatBots**:  [Copilot](https://copilot.microsoft.com/) which you have access to through your UofT account is already partially based on [ChatGPT4.0](https://chat.openai.com/) anyway...\n",
    "    >     - If your prompt is not sufficiently focused, and you instead use a more general initial prompt like, \"I need help analyzing my data\", you can subsequently request refinements and limitations to the scope of the responses of the ChatBot so it's dialogue is less broad and more responsive to your requested content targets\n",
    "\n",
    "    1. Use code provided in your ChatBot session in response to the prompts suggested above to print out the number of rows and columns of the dataset \n",
    "    2. Write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset  \n",
    "\n",
    "\n",
    "3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset\n",
    "    > If your prompt is not sufficiently focused, and you instead use a more general initial prompt like, \"I need help summarizing my data\", you can subsequently request refinements and limitations to the scope of the responses of the ChatBot so it's dialogue is less broad and more responsive to your requested content targets\n",
    "    > - Hint 1: consider dividing the code that ChatBot provides you into different jupyter notebook cells so that each cell concludes with a key printed result\n",
    "    > - Hint 2: the last line of code in a jupyter notebook cell will automatically print out in a formatted manner, so replacing something like `print(df.head())` with `df.head()` as the last line of a cell provides a sensible way to organize your code\n",
    "    > - Hint 3: jupyter notebook printouts usaully don't show all of the data (when there's too much to show, like if `df.describe()` include results for many columns), but the printouts just show enough of the data to give an idea of what the results are which is all we're looking for at the moment\n",
    "    >\n",
    "    > These \"Hints\" above are demonstrated in the **Course Project** section below the homework, if looking at an example would be helpful to understand what they're getting at...\n",
    "    > \n",
    "    > > ChatBots can suggest a wide variety of approaches and techniques for summarizing your dataset, so re-prompting the ChatBot with something like, \"What's the simplest form of summarization of this dataset that I could do and how do I do it in Python?\" or suggesting guidance using the specific summarization methods requested below can helpfully re-orient the ChatBot to your specific interests and needs\n",
    "    \n",
    "    1. Use your ChatBot session to help you create working examples of using  `df.describe()` and `df['column'].value_counts()` for your dataset\n",
    "        > The `.value_counts()` method is typically not used for numeric variables, so if you dataset has only numeric variables, this method might not be particularly informative\n",
    "\n",
    "                \n",
    "4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column\n",
    "    > If the dataset you're using does not have (a) non-numeric variables and (b) missing values in numeric variables (e.g., the `\"villagers.csv\"` example above has only a single numeric variable `row_n` which has no missing values), instead download and use the \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\" data to answer this question  \n",
    "    > - Hint 1: In (a) above, the \"columns it analyzes\" refers to the columns of the output of `df.describe()` which will only include \"numeric\" columns by default, but you can can see the names of all the columns in a dataset using `df.columns`\n",
    "    > - Hint 2: Make sure `df.shape` is refering to the dataset you think it is... if you've loaded a different dataset it might have a different name now!\n",
    "    >\n",
    "    > > #### If you get any errors, copy and paste them as a response to the ChatBot, and see if it can help you resove them by adding the suggested adjustments to your code and then reruning all your code to see if the changes have fixed the problem (and repeat this process as needed until the problems have been resolved).\n",
    "    \n",
    "    \n",
    "5. Use your ChatBot session to help understand the difference between an \"attribute\" (such as `df.shape` which does not end with `()`) and a \"method\" (such as `df.describe()` which does end with `()`) and provide your own paraphrasing summarization of that difference\n",
    "\n",
    "    > - Hint 1: The fact that a \"method\" (such as `df.describe()`) ends with `()` suggests that \"methods\" are essentially something that we would call a \"function\" in programming language terminology\n",
    "    > - Hint 2: Without getting too technical or \"in the weeds\" in your response, it might nonetheless be helpful to consider how you might describe what the difference is between what a \"function\" is in a programming language versus what a \"function\" is in mathematics \n",
    "\n",
    "    2. Ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea57fbf",
   "metadata": {},
   "source": [
    "#### *Feel free to work on the Postlecture HW below if you're making good progress and want to continue!*\n",
    "\n",
    "- In this case this, is particularly reasonable as questions \"6\" and \"7\" below directly follow up and extend the **Prelecture HW** questions\n",
    "    > The benefits of continue would are that (a) it might be fun to try to tackle the challenge of working through these questions without additional preparation or guidance; and (b) this is a very valable skill to be comfortable with; and (c) it will let you build experience interacting with ChatBots (and beginning to understand their strengths and limitations in this regard)... it's good to have sense of when using a ChatBot is the best way to figure something out, or if another approach (such as a plain old websearch for the right resourse, or course provided resources) would be better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d258e0",
   "metadata": {},
   "source": [
    "### Postlecture HW\n",
    "\n",
    "6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics \n",
    "    > - Hint: the answers here actually make it obvious why these can only be calculated for numeric variables in a dataset, which should help explain the answer to \"4(a)\" and \"4(b)\" above...\n",
    "    \n",
    "\n",
    "7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words.\n",
    "\n",
    "    > Start a new ChatBot session **[but remember to first ask your ChatBot for summaries of your current session and perhaps coding results (so you can supply these in the homework as requested)]**, since your last ChatBot session has likely gotten quite long and has covered a lot of material at this point. \n",
    "    > > It can sometimes be helpful to reset ChatBot sessions to refocus them on the topics of inquiry without too much backlog history that might unintentionally bias things in certain directions. Of course, you can always re-introduce material from earlier conversations as it's relevant, such as for answering \"D\" below based on reintroducing and updating code you made in a previous ChatBot session.  \n",
    "    > - Hint 1: More sophisticated analyses for \"filling in\" rather than removing missing data (as considered here) are possible (based on making assumptions about missing data and using specific imputation methods or models) but these are \"beyond the scope\" of this homework assignment so this topics can be safely ignored for now\n",
    "    > - Hint 2: This question is not interested in the general benefits of imputing missing data, or the general benefits of using `df.dropna()` and/or `del df['col']` to remove missing data, just how to most efficiently remove missing data if a user chooses to do so\n",
    "    >\n",
    "    > > **A key issue to be aware of when asking ChatBots for help with something is that they are not running and checking code for correctess, and they often intertwine written instructions with code instructions. BEFORE YOU RUN ANY CODE provided by a ChatBot, you should check the following:**\n",
    "    > > \n",
    "    > > 1. If this code changes an object or data, are you sure you want to run this code?\n",
    "    > > 2. Can you easily \"undo\" the results of running code (e.g., from a copy `df_saved=df.copy()` or reloading the data) if running the code doesn't do what you want?\n",
    "    > > 3. Is the state of the data what is expected by the code? Or have the objects been updated and changed so they're no longer what the code expects them to be? \n",
    "    > >\n",
    "    > > #### If you get any `Python` errors, copy and paste them into the ChatBot prompt and see if it can help you resove them.\n",
    "\n",
    "    1. Provide an example of a \"use case\" in which using `df.dropna()` might be peferred over using `del df['col']`\n",
    "    2. Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()` \n",
    "    3. Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important\n",
    "    4. Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset. \n",
    "\n",
    "\n",
    "<!-- 8. When we first used `df.describe()` above we had not yet explicitly removed the missing values from the dataset in the manner of the previous question above, but `df.describe()` seemed to work and provide results anyway... Assuming we're not going to fill in any missing data values using any missing data imputation methods, what's the one best argument for not explicitly removing missing values from a dataset? And alternatively, what's the one best argument for nonetheless explicitly removing missing values from a dataset? Give a simple summary in your own words explaining what you think the best arguments here are.\n",
    "\n",
    "    > - Hint 1: are you clear about what `df.describe()` does with the data in each columns it analyzes if there is missing data in the column in question? \n",
    "    > - Hint 2: are you sure all methods that we might want to apply to data will be able to handle missing data the way `df.describe()` does? -->\n",
    "    \n",
    "    \n",
    "8. This problem will guide you through exploring how to use a ChatBot to troubleshoot code using the \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\" data set. Give brief explanations in your own words for any requested answers to the questions below. \n",
    "    > To initialially constrain the scope of the reponses from your ChatChat, start a new ChatBot session with the following slight variation on the initial prompting approach from \"2\" above\n",
    "    > - \"I am going to do some initial simple summary analyses on the titanic data set I've downloaded (https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv) which has some missing values, and I'd like to get your help understanding the code I'm using and the analysis it's performing\"\n",
    "    > \n",
    "    > > Remember, ChatGPT will allow you to upload your data, but for this class we don't want ChatGPT to just do the analysis for us. **DO NOT purchase an upgrade of ChatGPT**. We instead want ChatBots to help us understand the steps we need to take to analyze the data. \n",
    "    > > - [Copilot Pro](https://copilot.microsoft.com/) which you have access to through your UofT account is anyway based on [ChatGPT4.0](https://chat.openai.com/)...   \n",
    "    \n",
    "    1. Use your ChatBot session to understand what `df.groupby(\"col1\")[\"col2\"].describe()` does and then demonstrate and explain this using a different example from your data set other than what the ChatBot automatically provide for you\n",
    "        > If needed, you can help guide the ChatBot by showing it the code you've used to download the data **AND provide it with the names of the columns** using either a summary of the data with `df.describe()` or just `df.columns` as demonstrated [here](../CHATLOG/COP/00017_copilot_groupby.md)\n",
    "    \n",
    "    2. Assuming you've not yet removed missing values in the manner of question \"7\" above, `df.describe()` would have different values in the `count` value for different data columns depending on the missingness present in the original data.  Why do these capture something fundamentally different from the values in the `count` that result from doing something like `df.groupby(\"col1\")[\"col2\"].describe()`?\n",
    "\n",
    "        > - Questions \"4\" and \"6\" above address how missing values are handled by `df.describe()` (which is reflected in the `count` output of this method); but, `count` in conjunction with `group_by` has another primary function that's more important than addressing missing values (although missing data could still play a role here).\n",
    "\n",
    "    3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors \n",
    "        > First share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT\n",
    "    \n",
    "        1. Forget to include `import pandas as pd` in your code \n",
    "            > Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "            >  - When python has an error, it sometimes provides a lot of \"stack trace\" output, but that's not usually very important for troubleshooting. For this problem for example, all you need to share with ChatGPT or search on google is `\"NameError: name 'pd' is not defined\"`\n",
    "\n",
    "        2. Mistype \"titanic.csv\" as \"titanics.csv\" \n",
    "            1. If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent `FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'` (assuming the file is indeed not present)\n",
    "            2. Explore introducing typos into a couple other parts of the url and note the slightly different errors this produces\n",
    "      \n",
    "        3. Try to use a dataframe before it's been assigned into the variable\n",
    "            > You can simulate this by just misnaming the variable. For example, if you should write `df.group_by(\"col1\")[\"col2\"].describe()` based on how you loaded the data, then instead write `DF.group_by(\"col1\")[\"col2\"].describe()`\n",
    "            > - Make sure you've fixed your file name so that's not the error any more\n",
    "        \n",
    "        4. Forget one of the parenthesis somewhere the code\n",
    "            > For example, if the code should be `pd.read_csv(url)` the change it to `pd.read_csv(url` \n",
    "        \n",
    "        5. Mistype one of the names of the chained functions with the code \n",
    "            > For example, try something like `df.group_by(\"col1\")[\"col2\"].describe()` and `df.groupby(\"col1\")[\"col2\"].describle()`\n",
    "        \n",
    "        6. Use a column name that's not in your data for the `groupby` and column selection \n",
    "            > For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in `titanic_df.groupby(\"sex\")[\"age\"].describe()`, and then instead introducing the same error of \"age\"\n",
    "        \n",
    "        7. Forget to put the column name as a string in quotes for the `groupby` and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "            > For example, something like `titanic_df.groupby(sex)[\"age\"].describe()`, and then `titanic_df.groupby(\"sex\")[age].describe()`\n",
    "    \n",
    "\n",
    "9. Have you reviewed the course [wiki-textbook](https://github.com/pointOfive/STA130_ChatGPT/wiki) and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it? \n",
    "> Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe21941",
   "metadata": {},
   "source": [
    "## Ethical Professionalism\n",
    "\n",
    "If the observed data is \"no events occured\" does this mean the data is \"missing\" and [should be ignored](https://priceonomics.com/the-space-shuttle-challenger-explosion-and-the-o)?\n",
    "\n",
    "- NASA: \\<determines temperature doesn't affects \"o-ring\" by subseting data to just \"o-ring\" incidents\\>\n",
    "- Also NASA: \\<launches the shuttle on a cold day\\>\n",
    "\n",
    "|No apparent \"o-ring\" failure and temperature relationship|Apparent between \"o-ring\" failure and temperature relationship|\n",
    "|:-|:-|\n",
    "|if you just look at \"o-ring\" failure event data|if you instead look at ALL the data as you should|\n",
    "|![](https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/image06-14.png)|![](https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/image02-33.png)|\n",
    "|![](https://upload.wikimedia.org/wikipedia/commons/8/8b/Shuttle_Challenger_explosion.gif?20190203170223)|![](https://i.makeagif.com/media/10-04-2014/nT57xW.gif)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066181d6",
   "metadata": {},
   "source": [
    "## Course Project\n",
    "\n",
    "The data we'll use for the STA130 course project is based on the [2024 Canadian Social Connection Survey](https://casch.org/cscs). Please see the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) regarding the appropriate and ethical professional use of this data.\n",
    "\n",
    "1. Have a look at the list of available variables [here](/Users/scottschwartz/Downloads/var_names.csv)\n",
    "2. Use the code below to have a look at the data itself [here](/Users/scottschwartz/Downloads/CSCS_data_anon.csv)\n",
    "3. Consider which variables seem interesting and whether or not they have a lot of missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38a85a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/hnfh4zsn34d7xpbz9226pz200000gn/T/ipykernel_81003/2230918422.py:3: DtypeWarning: Columns (408,1001,1002,1006,1007,1008,1080,1113,1115,1116,1117,1118,1119,1120,1121,1124,1125,1126,1127,1128,1213,1214,1215,1216,1217,1218,1342,1343,1344,1345,1346,1347,1348,1349,1390,1391,1393,1463,1549,1552,1555,1558,1561) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"/Users/scottschwartz/Downloads/CSCS_data_anon.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11431, 1794)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols = pd.read_csv(\"/Users/scottschwartz/Downloads/var_names.csv\")\n",
    "data = pd.read_csv(\"/Users/scottschwartz/Downloads/CSCS_data_anon.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d7b4051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11431, 132)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingness_limit = 5000\n",
    "data[data.isna().sum().index[dats.isna().sum() < missingness_limit]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7ab704c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUE_id</th>\n",
       "      <th>UNIQUE_num_records</th>\n",
       "      <th>ELIGIBLE_consent</th>\n",
       "      <th>GEO_residence_canada</th>\n",
       "      <th>GEO_province</th>\n",
       "      <th>DEMO_age</th>\n",
       "      <th>DEMO_gender</th>\n",
       "      <th>DEMO_identity_lgbtq</th>\n",
       "      <th>DEMO_relationship_status</th>\n",
       "      <th>COVID_prevention_distancing</th>\n",
       "      <th>...</th>\n",
       "      <th>LONELY_dejong_emotional_loneliness_sub_scale_score</th>\n",
       "      <th>LONELY_dejong_social_loneliness_sub_scale_score</th>\n",
       "      <th>LONELY_dejong_emotional_social_loneliness_scale_score_y_n</th>\n",
       "      <th>LONELY_dejong_emotional_loneliness_sub_scale_score_y_n</th>\n",
       "      <th>LONELY_dejong_social_loneliness_sub_scale_score_y_n</th>\n",
       "      <th>WELLNESS_phq_score</th>\n",
       "      <th>WELLNESS_phq_score_y_n</th>\n",
       "      <th>WELLNESS_gad_score</th>\n",
       "      <th>WELLNESS_gad_score_y_n</th>\n",
       "      <th>REMOVE_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cscs_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Sexual or gender minorities (e.g., LGBTQ2+)</td>\n",
       "      <td>Single and not dating</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cscs_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-1)</td>\n",
       "      <td>No (0)</td>\n",
       "      <td>No (0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cscs_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>Single and not dating</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cscs_00005</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cscs_00006</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>Sexual or gender minorities (e.g., LGBTQ2+)</td>\n",
       "      <td>Single and dating</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>cscs_11809</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Sexual or gender minorities (e.g., LGBTQ2+)</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>cscs_11810</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-1)</td>\n",
       "      <td>No (0)</td>\n",
       "      <td>No (0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>Single and not dating</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (2-6)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>Yes (1-3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11431 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNIQUE_id  UNIQUE_num_records ELIGIBLE_consent GEO_residence_canada  \\\n",
       "0      cscs_00001                   1              Yes                  Yes   \n",
       "1      cscs_00002                   1              Yes                  Yes   \n",
       "2      cscs_00003                   1              Yes                  Yes   \n",
       "3      cscs_00005                   1              Yes                  Yes   \n",
       "4      cscs_00006                   1              Yes                  Yes   \n",
       "...           ...                 ...              ...                  ...   \n",
       "11426  cscs_11809                   1              Yes                  Yes   \n",
       "11427  cscs_11810                   1              Yes                  Yes   \n",
       "11428  cscs_11812                   3              Yes                  NaN   \n",
       "11429  cscs_11812                   3              Yes                  NaN   \n",
       "11430  cscs_11812                   3              Yes                  Yes   \n",
       "\n",
       "           GEO_province  DEMO_age DEMO_gender  \\\n",
       "0      British Columbia      71.0  Non-binary   \n",
       "1               Ontario      69.0       Woman   \n",
       "2                Quebec      56.0       Woman   \n",
       "3                   NaN      54.0       Woman   \n",
       "4               Ontario      30.0         Man   \n",
       "...                 ...       ...         ...   \n",
       "11426               NaN      45.0       Woman   \n",
       "11427  British Columbia      36.0         Man   \n",
       "11428               NaN       NaN         NaN   \n",
       "11429               NaN       NaN         NaN   \n",
       "11430           Ontario      31.0       Woman   \n",
       "\n",
       "                               DEMO_identity_lgbtq DEMO_relationship_status  \\\n",
       "0      Sexual or gender minorities (e.g., LGBTQ2+)    Single and not dating   \n",
       "1                                     Not Selected        In a relationship   \n",
       "2                                     Not Selected    Single and not dating   \n",
       "3                                     Not Selected        In a relationship   \n",
       "4      Sexual or gender minorities (e.g., LGBTQ2+)        Single and dating   \n",
       "...                                            ...                      ...   \n",
       "11426  Sexual or gender minorities (e.g., LGBTQ2+)        In a relationship   \n",
       "11427                                 Not Selected        In a relationship   \n",
       "11428                                          NaN                      NaN   \n",
       "11429                                          NaN                      NaN   \n",
       "11430                                 Not Selected    Single and not dating   \n",
       "\n",
       "      COVID_prevention_distancing  ...  \\\n",
       "0                Somewhat closely  ...   \n",
       "1                    Very closely  ...   \n",
       "2                Somewhat closely  ...   \n",
       "3                      Not at all  ...   \n",
       "4                    Very closely  ...   \n",
       "...                           ...  ...   \n",
       "11426            Somewhat closely  ...   \n",
       "11427                  Not at all  ...   \n",
       "11428            Somewhat closely  ...   \n",
       "11429                  Not at all  ...   \n",
       "11430                Very closely  ...   \n",
       "\n",
       "      LONELY_dejong_emotional_loneliness_sub_scale_score  \\\n",
       "0                                                    2.0   \n",
       "1                                                    0.0   \n",
       "2                                                    1.0   \n",
       "3                                                    3.0   \n",
       "4                                                    1.0   \n",
       "...                                                  ...   \n",
       "11426                                                1.0   \n",
       "11427                                                0.0   \n",
       "11428                                                2.0   \n",
       "11429                                                1.0   \n",
       "11430                                                1.0   \n",
       "\n",
       "      LONELY_dejong_social_loneliness_sub_scale_score  \\\n",
       "0                                                 3.0   \n",
       "1                                                 0.0   \n",
       "2                                                 1.0   \n",
       "3                                                 3.0   \n",
       "4                                                 2.0   \n",
       "...                                               ...   \n",
       "11426                                             3.0   \n",
       "11427                                             0.0   \n",
       "11428                                             2.0   \n",
       "11429                                             3.0   \n",
       "11430                                             3.0   \n",
       "\n",
       "      LONELY_dejong_emotional_social_loneliness_scale_score_y_n  \\\n",
       "0                                              Yes (2-6)          \n",
       "1                                               No (0-1)          \n",
       "2                                              Yes (2-6)          \n",
       "3                                              Yes (2-6)          \n",
       "4                                              Yes (2-6)          \n",
       "...                                                  ...          \n",
       "11426                                          Yes (2-6)          \n",
       "11427                                           No (0-1)          \n",
       "11428                                          Yes (2-6)          \n",
       "11429                                          Yes (2-6)          \n",
       "11430                                          Yes (2-6)          \n",
       "\n",
       "      LONELY_dejong_emotional_loneliness_sub_scale_score_y_n  \\\n",
       "0                                              Yes (1-3)       \n",
       "1                                                 No (0)       \n",
       "2                                              Yes (1-3)       \n",
       "3                                              Yes (1-3)       \n",
       "4                                              Yes (1-3)       \n",
       "...                                                  ...       \n",
       "11426                                          Yes (1-3)       \n",
       "11427                                             No (0)       \n",
       "11428                                          Yes (1-3)       \n",
       "11429                                          Yes (1-3)       \n",
       "11430                                          Yes (1-3)       \n",
       "\n",
       "      LONELY_dejong_social_loneliness_sub_scale_score_y_n WELLNESS_phq_score  \\\n",
       "0                                              Yes (1-3)                 5.0   \n",
       "1                                                 No (0)                 0.0   \n",
       "2                                              Yes (1-3)                 0.0   \n",
       "3                                              Yes (1-3)                 4.0   \n",
       "4                                              Yes (1-3)                 0.0   \n",
       "...                                                  ...                 ...   \n",
       "11426                                          Yes (1-3)                 0.0   \n",
       "11427                                             No (0)                 1.0   \n",
       "11428                                          Yes (1-3)                 3.0   \n",
       "11429                                          Yes (1-3)                 2.0   \n",
       "11430                                          Yes (1-3)                 1.0   \n",
       "\n",
       "       WELLNESS_phq_score_y_n WELLNESS_gad_score WELLNESS_gad_score_y_n  \\\n",
       "0                   Yes (3-6)                5.0              Yes (3-6)   \n",
       "1                    No (0-2)                0.0               No (0-2)   \n",
       "2                    No (0-2)                3.0              Yes (3-6)   \n",
       "3                   Yes (3-6)                2.0               No (0-2)   \n",
       "4                    No (0-2)                1.0               No (0-2)   \n",
       "...                       ...                ...                    ...   \n",
       "11426                No (0-2)                0.0               No (0-2)   \n",
       "11427                No (0-2)                3.0              Yes (3-6)   \n",
       "11428               Yes (3-6)                2.0               No (0-2)   \n",
       "11429                No (0-2)                3.0              Yes (3-6)   \n",
       "11430                No (0-2)                1.0               No (0-2)   \n",
       "\n",
       "      REMOVE_case  \n",
       "0              No  \n",
       "1              No  \n",
       "2              No  \n",
       "3              No  \n",
       "4              No  \n",
       "...           ...  \n",
       "11426          No  \n",
       "11427          No  \n",
       "11428          No  \n",
       "11429         Yes  \n",
       "11430          No  \n",
       "\n",
       "[11431 rows x 132 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isna().sum().index[dats.isna().sum() < missingness_limit]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c25d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CONNECTION_activities_new_friend_pm',\n",
       "       'CONNECTION_activities_coffee_pm',\n",
       "       'CONNECTION_activities_discussion_group_pm',\n",
       "       'CONNECTION_activities_group_exercise_pm',\n",
       "       'CONNECTION_activities_checked_in_pm',\n",
       "       'CONNECTION_activities_visited_family_pm',\n",
       "       'CONNECTION_activities_visited_friends_pm',\n",
       "       'CONNECTION_activities_community_pm', 'CONNECTION_activities_walk_pm',\n",
       "       'CONNECTION_activities_games_pm', 'CONNECTION_activities_talked_pm',\n",
       "       'SURVEY_num_surveys', 'Num_answered', 'Secs_per_q',\n",
       "       'LONELY_dejong_emotional_social_loneliness_scale_score',\n",
       "       'LONELY_dejong_emotional_loneliness_sub_scale_score',\n",
       "       'LONELY_dejong_social_loneliness_sub_scale_score',\n",
       "       'LONELY_dejong_emotional_social_loneliness_scale_score_y_n',\n",
       "       'LONELY_dejong_emotional_loneliness_sub_scale_score_y_n',\n",
       "       'LONELY_dejong_social_loneliness_sub_scale_score_y_n',\n",
       "       'WELLNESS_phq_score', 'WELLNESS_phq_score_y_n', 'WELLNESS_gad_score',\n",
       "       'WELLNESS_gad_score_y_n', 'REMOVE_case'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_missingness_limit = data[data.isna().sum().index[dats.isna().sum() < missingness_limit]].columns\n",
    "\n",
    "cols_missingness_limit[0:25] # first twenty-five columns\n",
    "cols_missingness_limit[25:50] # next twenty-five columns\n",
    "cols_missingness_limit[107:132] # last twenty-five columns \n",
    "                                # (assuming `missingness_limit = 5000` and 132 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fc13292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUE_id</th>\n",
       "      <th>UNIQUE_num_records</th>\n",
       "      <th>ELIGIBLE_consent</th>\n",
       "      <th>GEO_residence_canada</th>\n",
       "      <th>GEO_province</th>\n",
       "      <th>DEMO_age</th>\n",
       "      <th>DEMO_gender</th>\n",
       "      <th>DEMO_identity_lgbtq</th>\n",
       "      <th>DEMO_relationship_status</th>\n",
       "      <th>COVID_prevention_distancing</th>\n",
       "      <th>...</th>\n",
       "      <th>COVID_vaccinated</th>\n",
       "      <th>WELLNESS_life_satisfaction</th>\n",
       "      <th>CONNECTION_activities_phone_p3m</th>\n",
       "      <th>CONNECTION_activities_text_or_messaged_p3m</th>\n",
       "      <th>CONNECTION_activities_chat_p3m</th>\n",
       "      <th>CONNECTION_activities_group_video_chat_p3m</th>\n",
       "      <th>CONNECTION_activities_walk_p3m</th>\n",
       "      <th>CONNECTION_activities_coffee_p3m</th>\n",
       "      <th>CONNECTION_activities_computer_games_p3m</th>\n",
       "      <th>CONNECTION_activities_visited_friends_p3m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cscs_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Sexual or gender minorities (e.g., LGBTQ2+)</td>\n",
       "      <td>Single and not dating</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, three or more doses</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cscs_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, three or more doses</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cscs_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>Single and not dating</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, three or more doses</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cscs_00005</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, three or more doses</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>A few times a week</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>A few times a week</td>\n",
       "      <td>A few times a week</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cscs_00006</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>Sexual or gender minorities (e.g., LGBTQ2+)</td>\n",
       "      <td>Single and dating</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, one dose</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>A few times a week</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>A few times a week</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>cscs_11809</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Sexual or gender minorities (e.g., LGBTQ2+)</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, three or more doses</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>A few times a week</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Not in the past three months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>cscs_11810</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, three or more doses</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, two doses</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Less than monthly</td>\n",
       "      <td>Less than monthly</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Not in the past three months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, two doses</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A few times a month</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Less than monthly</td>\n",
       "      <td>Less than monthly</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Not in the past three months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>Single and not dating</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Daily or almost daily</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>A few times a month</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Not in the past three months</td>\n",
       "      <td>Not in the past three months</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11431 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNIQUE_id  UNIQUE_num_records ELIGIBLE_consent GEO_residence_canada  \\\n",
       "0      cscs_00001                   1              Yes                  Yes   \n",
       "1      cscs_00002                   1              Yes                  Yes   \n",
       "2      cscs_00003                   1              Yes                  Yes   \n",
       "3      cscs_00005                   1              Yes                  Yes   \n",
       "4      cscs_00006                   1              Yes                  Yes   \n",
       "...           ...                 ...              ...                  ...   \n",
       "11426  cscs_11809                   1              Yes                  Yes   \n",
       "11427  cscs_11810                   1              Yes                  Yes   \n",
       "11428  cscs_11812                   3              Yes                  NaN   \n",
       "11429  cscs_11812                   3              Yes                  NaN   \n",
       "11430  cscs_11812                   3              Yes                  Yes   \n",
       "\n",
       "           GEO_province  DEMO_age DEMO_gender  \\\n",
       "0      British Columbia      71.0  Non-binary   \n",
       "1               Ontario      69.0       Woman   \n",
       "2                Quebec      56.0       Woman   \n",
       "3                   NaN      54.0       Woman   \n",
       "4               Ontario      30.0         Man   \n",
       "...                 ...       ...         ...   \n",
       "11426               NaN      45.0       Woman   \n",
       "11427  British Columbia      36.0         Man   \n",
       "11428               NaN       NaN         NaN   \n",
       "11429               NaN       NaN         NaN   \n",
       "11430           Ontario      31.0       Woman   \n",
       "\n",
       "                               DEMO_identity_lgbtq DEMO_relationship_status  \\\n",
       "0      Sexual or gender minorities (e.g., LGBTQ2+)    Single and not dating   \n",
       "1                                     Not Selected        In a relationship   \n",
       "2                                     Not Selected    Single and not dating   \n",
       "3                                     Not Selected        In a relationship   \n",
       "4      Sexual or gender minorities (e.g., LGBTQ2+)        Single and dating   \n",
       "...                                            ...                      ...   \n",
       "11426  Sexual or gender minorities (e.g., LGBTQ2+)        In a relationship   \n",
       "11427                                 Not Selected        In a relationship   \n",
       "11428                                          NaN                      NaN   \n",
       "11429                                          NaN                      NaN   \n",
       "11430                                 Not Selected    Single and not dating   \n",
       "\n",
       "      COVID_prevention_distancing  ...          COVID_vaccinated  \\\n",
       "0                Somewhat closely  ...  Yes, three or more doses   \n",
       "1                    Very closely  ...  Yes, three or more doses   \n",
       "2                Somewhat closely  ...  Yes, three or more doses   \n",
       "3                      Not at all  ...  Yes, three or more doses   \n",
       "4                    Very closely  ...             Yes, one dose   \n",
       "...                           ...  ...                       ...   \n",
       "11426            Somewhat closely  ...  Yes, three or more doses   \n",
       "11427                  Not at all  ...  Yes, three or more doses   \n",
       "11428            Somewhat closely  ...            Yes, two doses   \n",
       "11429                  Not at all  ...            Yes, two doses   \n",
       "11430                Very closely  ...                        No   \n",
       "\n",
       "      WELLNESS_life_satisfaction CONNECTION_activities_phone_p3m  \\\n",
       "0                            2.0                             NaN   \n",
       "1                            7.0                             NaN   \n",
       "2                            5.0                             NaN   \n",
       "3                            4.0           Daily or almost daily   \n",
       "4                            8.0           Daily or almost daily   \n",
       "...                          ...                             ...   \n",
       "11426                       10.0           Daily or almost daily   \n",
       "11427                        8.0                             NaN   \n",
       "11428                        4.0           Daily or almost daily   \n",
       "11429                        5.0             A few times a month   \n",
       "11430                        7.0           Daily or almost daily   \n",
       "\n",
       "      CONNECTION_activities_text_or_messaged_p3m  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                             A few times a week   \n",
       "4                                        Monthly   \n",
       "...                                          ...   \n",
       "11426                      Daily or almost daily   \n",
       "11427                                        NaN   \n",
       "11428                      Daily or almost daily   \n",
       "11429                                     Weekly   \n",
       "11430                      Daily or almost daily   \n",
       "\n",
       "      CONNECTION_activities_chat_p3m  \\\n",
       "0                                NaN   \n",
       "1                                NaN   \n",
       "2                                NaN   \n",
       "3              Daily or almost daily   \n",
       "4                             Weekly   \n",
       "...                              ...   \n",
       "11426          Daily or almost daily   \n",
       "11427                            NaN   \n",
       "11428          Daily or almost daily   \n",
       "11429          Daily or almost daily   \n",
       "11430          Daily or almost daily   \n",
       "\n",
       "      CONNECTION_activities_group_video_chat_p3m  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                        Monthly   \n",
       "4                             A few times a week   \n",
       "...                                          ...   \n",
       "11426                      Daily or almost daily   \n",
       "11427                                        NaN   \n",
       "11428               Not in the past three months   \n",
       "11429               Not in the past three months   \n",
       "11430               Not in the past three months   \n",
       "\n",
       "       CONNECTION_activities_walk_p3m CONNECTION_activities_coffee_p3m  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              NaN   \n",
       "3                  A few times a week               A few times a week   \n",
       "4                              Weekly                           Weekly   \n",
       "...                               ...                              ...   \n",
       "11426           Daily or almost daily               A few times a week   \n",
       "11427                             NaN                              NaN   \n",
       "11428               Less than monthly                Less than monthly   \n",
       "11429               Less than monthly                Less than monthly   \n",
       "11430             A few times a month     Not in the past three months   \n",
       "\n",
       "      CONNECTION_activities_computer_games_p3m  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                      Monthly   \n",
       "4                           A few times a week   \n",
       "...                                        ...   \n",
       "11426             Not in the past three months   \n",
       "11427                                      NaN   \n",
       "11428             Not in the past three months   \n",
       "11429             Not in the past three months   \n",
       "11430             Not in the past three months   \n",
       "\n",
       "      CONNECTION_activities_visited_friends_p3m  \n",
       "0                                           NaN  \n",
       "1                                           NaN  \n",
       "2                                           NaN  \n",
       "3                                       Monthly  \n",
       "4                                        Weekly  \n",
       "...                                         ...  \n",
       "11426              Not in the past three months  \n",
       "11427                                       NaN  \n",
       "11428              Not in the past three months  \n",
       "11429              Not in the past three months  \n",
       "11430              Not in the past three months  \n",
       "\n",
       "[11431 rows x 25 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isna().sum().index[dats.isna().sum() < missingness_limit]][cols_missingness_limit[0:25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca7d22",
   "metadata": {},
   "source": [
    "#### Afterward\n",
    "\n",
    "Here are few ideas of some other kinds of interactions you might consider exploring with ChatGPT...\n",
    "\n",
    "> While these are likely to be extremely practically valuable, they are not a part of the homework assignment, so do not include anything related to these in your homework submission\n",
    "\n",
    "- With respect to improving ones ability in statistics, coding, communication, and other key data science skills\n",
    "    - what is ChatGPTs perception its own capabilities and uses as an AI-driven assistance tool \n",
    "    - and does ChatGPTs assessment of itself influence or agree with your own evalution of ChatGPT? \n",
    "\n",
    "- ChatGPT can introduce and explain the \"World War 2 planes\" problem and the \"Monte Hall\" problem... \n",
    "    - how well does it seem to do and showing and explain other \"unintuitive surprising statistics paradoxes\"?\n",
    "\n",
    "- If you consider the process of writing about why you chose to take this course, and the skills you were hoping to build through this course with respect to your current ideas about what possible careers \n",
    "    - and how do you think the exercise would be different if you framed it as a dialogue with ChatGPT\n",
    "    - and do you think the difference could be positive and productive, or potentially biasing and distracting?\n",
    "    \n",
    "- ChatGPT sometimes immediately responds in simple helpful ways, but other times it gives a lot of information that can be overwheling... are you able to prompt and interact with ChatGPT in manner that keeps its reponses helpful and focused on what you're interested in? \n",
    "\n",
    "- ChatGPT tends to respond in a fairly empathetic and supportive tone...\n",
    "    - do you find it helpful to discuss concerns you might have about succeeding in the course (or entering university more generally) with ChatGPT?\n",
    "    \n",
    "- For what purposes and in what contexts do you think ChatGPT could provide suggestions or feedback about your experiences that might be useful? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
